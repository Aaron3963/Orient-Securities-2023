{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Timestamp', 'Open', 'High', 'Low', 'Volume', 'Turnover', 'Close',\n",
      "       'Avg', 'log_ret_close_1min', 'MACD_close_F12S26S9', 'RSI_close_12min',\n",
      "       'log_ret_avg_1min', 'MACD_avg_F12S26S9', 'RSI_avg_12min', 'SAR',\n",
      "       'BB_hit_wall', 'Target_Close_1min', 'Target_Avg_1min',\n",
      "       'Target_Close_5min', 'Target_Avg_5min', 'STOCK_log_ret_close_1min',\n",
      "       'STOCK_MACD_close_F12S26S9', 'STOCK_RSI_close_12min',\n",
      "       'STOCK_log_ret_avg_1min', 'STOCK_MACD_avg_F12S26S9',\n",
      "       'STOCK_RSI_avg_12min', 'STOCK_SAR', 'STOCK_BB_hit_wall'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "TRAIN_PATH = '123181_train_withF_cutMax.csv'\n",
    "TEST_PATH = '123181_test_withF.csv'\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming dataframe to TSFresh format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Local\\Temp\\ipykernel_31980\\2584507302.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_X['Timestamp'] = pd.to_datetime(train_X['Timestamp'])\n"
     ]
    }
   ],
   "source": [
    "train_X = train[['Timestamp', 'Open', 'High', 'Low', 'Volume', 'Turnover', 'Close']]\n",
    "\n",
    "# Avg', 'log_ret_close_1min', 'MACD_close_F12S26S9', 'RSI_close_12min',\n",
    "       # 'BB_hit_wall', 'STOCK_log_ret_close_1min',\n",
    "       # 'STOCK_MACD_close_F12S26S9', 'STOCK_RSI_close_12min',\n",
    "       # 'STOCK_BB_hit_wall'\n",
    "\n",
    "train_y = train['Target_Close_1min']\n",
    "\n",
    "train_X['Timestamp'] = pd.to_datetime(train_X['Timestamp'])\n",
    "\n",
    "# train_X.rename(columns={'Timestamp': 'time'}, inplace=True)\n",
    "\n",
    "train_X.insert(loc=0, column='id', value=123181)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 6/6 [00:43<00:00,  7.26s/it]\n",
      "c:\\Users\\Aaron\\anaconda3\\lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:198: RuntimeWarning: The columns ['Volume__query_similarity_count__query_None__threshold_0.0'\n",
      " 'High__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Low__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Open__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Close__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Turnover__query_similarity_count__query_None__threshold_0.0'] did not have any finite values. Filling with zeros.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4698)\n",
      "(5507,)\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features,select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "extracted_features = extract_features(train_X, column_id=\"id\", column_sort=\"Timestamp\")\n",
    "impute(extracted_features)\n",
    "\n",
    "\n",
    "print(extracted_features.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Volume__variance_larger_than_standard_deviation  \\\n",
      "123181                                              1.0   \n",
      "\n",
      "        Volume__has_duplicate_max  Volume__has_duplicate_min  \\\n",
      "123181                        0.0                        1.0   \n",
      "\n",
      "        Volume__has_duplicate  Volume__sum_values  Volume__abs_energy  \\\n",
      "123181                    1.0         322608642.0        6.353186e+13   \n",
      "\n",
      "        Volume__mean_abs_change  Volume__mean_change  \\\n",
      "123181             22923.610243             1.994188   \n",
      "\n",
      "        Volume__mean_second_derivative_central  Volume__median  ...  \\\n",
      "123181                               -0.335876         27440.0  ...   \n",
      "\n",
      "        Turnover__fourier_entropy__bins_5  Turnover__fourier_entropy__bins_10  \\\n",
      "123181                           0.170467                            0.357079   \n",
      "\n",
      "        Turnover__fourier_entropy__bins_100  \\\n",
      "123181                             1.636682   \n",
      "\n",
      "        Turnover__permutation_entropy__dimension_3__tau_1  \\\n",
      "123181                                           1.768967   \n",
      "\n",
      "        Turnover__permutation_entropy__dimension_4__tau_1  \\\n",
      "123181                                           3.109228   \n",
      "\n",
      "        Turnover__permutation_entropy__dimension_5__tau_1  \\\n",
      "123181                                           4.639517   \n",
      "\n",
      "        Turnover__permutation_entropy__dimension_6__tau_1  \\\n",
      "123181                                           6.282066   \n",
      "\n",
      "        Turnover__permutation_entropy__dimension_7__tau_1  \\\n",
      "123181                                           7.705097   \n",
      "\n",
      "        Turnover__query_similarity_count__query_None__threshold_0.0  \\\n",
      "123181                                                0.0             \n",
      "\n",
      "        Turnover__mean_n_absolute_max__number_of_maxima_7  \n",
      "123181                                       2.016521e+08  \n",
      "\n",
      "[1 rows x 4698 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(extracted_features)\n\u001b[1;32m----> 2\u001b[0m extract_features\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39m\u001b[39mtemp.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "print(extracted_features)\n",
    "extract_features.to_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filtered = select_features(extracted_features, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
